# -*- coding: utf-8 -*-
"""cancer_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wipdg0tQ2E_5snuM5cpMani0bgyi6aFH
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
data = pd.read_csv("/content/drive/MyDrive/data.csv")

"""Pandas dataframe: a data structure used by Pandas to store tabular data"""

data

training_data_len = int(0.7 * len(data))
testing_data_len = len(data) - training_data_len
print(training_data_len, testing_data_len)

data[["id", "diagnosis"]] # to print specific rows

# using boolean masking
neg_class_data = data[data["diagnosis"] == 'B']
pos_class_data = data[data["diagnosis"] == 'M']
train_neg_class_data = neg_class_data.iloc[0:training_data_len//2, :]
train_pos_class_data = pos_class_data.iloc[0:training_data_len//2, :]
test_neg_class_data = neg_class_data.iloc[training_data_len//2:, :]
test_pos_class_data = pos_class_data.iloc[training_data_len//2:, :]

print(train_neg_class_data.shape)
print(train_pos_class_data.shape)
print(test_neg_class_data.shape)
print(test_pos_class_data.shape)

# axis=0 is y-axis and axis=1 is x-axis
training_data = pd.concat([train_neg_class_data, train_pos_class_data], axis=0)
testing_data = pd.concat([test_neg_class_data, test_pos_class_data], axis=0)

training_data = training_data.drop([data.columns[32]], axis=1)
testing_data = testing_data.drop([data.columns[32]], axis=1)

data.columns

training_data.shape

testing_data.shape

# plotting two columns of the dataset
import matplotlib.pyplot as plt
plt.scatter(training_data[training_data.columns[2]], training_data[training_data.columns[3]])



# for i in range(0, len(training_data.columns)):
#   for j in range(0, len(training_data.columns)):
#     if not i == j:
#       plt.scatter(training_data[training_data.columns[i]], training_data[training_data.columns[j]])

training_data.corr()

training_data[training_data.columns[1]].replace(to_replace=['B', 'M'], value=[0, 1], inplace=True)

training_data

testing_data[testing_data.columns[1]].replace(to_replace=['B', 'M'], value=[0, 1], inplace=True)
testing_data

corr_matrix = training_data.corr()
corr_matrix

corr_matrix[training_data.columns[1]] > 0.5

D = dict(corr_matrix[training_data.columns[1]] > 0.5)

filtered_columns = []
for col in list(D.keys()):
  if D[col] == True:
    filtered_columns.append(col)
filtered_columns

"""**Applying feature selection:** It is the process of selecting only relevant input features from a dataset for further processign and analysis.

**Dimensionality reduction**
Total number of input features in the dataset is called the **dimension of the dataset**.
"""

filtered_training_data = training_data[filtered_columns]
filtered_training_data

"""Data cleaning completed.
Model Training starts now using NaiveBayes algo.

NaiveBayes is a **classification** algorithm.
"""

from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression

answers = filtered_training_data[data.columns[1]]
answers

input_features = filtered_training_data.drop(data.columns[1], axis=1)
input_features

naive_bayes_algo = GaussianNB() # create an object of GaussianNB
naive_bayes_algo.fit(X=input_features, y=answers) # training the model on the train data

filtered_testing_data = testing_data[filtered_columns]

filtered_testing_data

testing_answers = filtered_testing_data[data.columns[1]]
testing_input_features = filtered_testing_data.drop(data.columns[1], axis=1)

# testing the trained model
exam_answers = naive_bayes_algo.predict(X=testing_input_features)
# exam_answers = naive_bayes_algo.predict(X=input_features.iloc[0:171, :])

exam_answers

# comparing the original and obtained values
from sklearn.metrics import classification_report
report = classification_report(y_true=testing_answers, y_pred=exam_answers)

"""**Final Report**"""

print(report)

