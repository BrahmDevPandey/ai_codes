# -*- coding: utf-8 -*-
"""cancer_prediction_assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xoiMsio714U0q4tXdp4r5SSgCvKvr8Nm

**Step 1**: Mount drive for accessing the csv file
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Step 2**: Load the csv file into a pandas dataframe"""

import pandas as pd
data = pd.read_csv("/content/drive/MyDrive/data.csv")

"""Pandas dataframe: a data structure used by Pandas to store tabular data

See the whole data in the dataframe
"""

data

"""**Step 3**: Now find the lenghts of training and testing data sets by dividing the initial dataset into two parts in ratio 70%:30% for training and testing, respectively."""

training_data_len = int(0.7 * len(data))
testing_data_len = len(data) - training_data_len
print(training_data_len, testing_data_len)

"""**Step 4**: Find the lengths of positive (having Benign) and negative (having Malignant) results in the training and testing data"""

# using boolean masking
neg_class_data = data[data["diagnosis"] == 'B']
pos_class_data = data[data["diagnosis"] == 'M']
train_neg_class_data = neg_class_data.iloc[0:training_data_len//2, :]
train_pos_class_data = pos_class_data.iloc[0:training_data_len//2, :]
test_neg_class_data = neg_class_data.iloc[training_data_len//2:, :]
test_pos_class_data = pos_class_data.iloc[training_data_len//2:, :]

"""See the size of each of the dataframes"""

print(train_neg_class_data.shape)
print(train_pos_class_data.shape)
print(test_neg_class_data.shape)
print(test_pos_class_data.shape)

# axis=0 is y-axis and axis=1 is x-axis
training_data = pd.concat([train_neg_class_data, train_pos_class_data], axis=0)
testing_data = pd.concat([test_neg_class_data, test_pos_class_data], axis=0)

training_data = training_data.drop([data.columns[32]], axis=1)
testing_data = testing_data.drop([data.columns[32]], axis=1)

data.columns

training_data.shape

testing_data.shape

"""See a basic plot of relation between any two columns of the dataframe"""

# plotting two columns of the dataset
import matplotlib.pyplot as plt
plt.scatter(training_data[training_data.columns[2]], training_data[training_data.columns[3]])

"""**Step 5**: See the Pearson Correlation Coefficient of all the columns with each other."""

training_data.corr()

"""**Step 6**: Now, we have to convert all the value of diagnosis field of training dataset to some integer values since Gaussian NaviveBayes classifier does not work on String values.

And since the values B (for Benign) and M (for Malign) are nominal strings and not cardinal strings, we can assign arbitrary numbers to them. Therefore, we will replace 'B' with 0 and 'M' with 1.
"""

training_data[training_data.columns[1]].replace(to_replace=['B', 'M'], value=[0, 1], inplace=True)

"""Now have a look at the training data columns after replacement."""

training_data

"""**Step 7**: Perform the same replacement operation in testing dataset also."""

testing_data[testing_data.columns[1]].replace(to_replace=['B', 'M'], value=[0, 1], inplace=True)
testing_data

"""**Step 8**: Now, we will calculate the new Pearson Correlation Coefficient of the training dataset and store it into a matrix `corr_matrix`"""

corr_matrix = training_data.corr()

"""**Step 9**: This step will deal with feature selection process.
**Feature selection** is a step of data cleaning in which we identify the attributes of the data that are more relevant to the final result `diagnosis`.
Here, the columns will be filtered on the basis of their Pearson Correlation Coefficient with `diagnosis`.

**For example**, we will use a random value `0.5` as the lower limit of Pearson Correlation Coefficient (PCC) to filter out the columns that have their PCC less than `0.5`.

For achieving this, we will use **Boolean masking** to filter out the less correlated columns.
"""

corr_matrix[training_data.columns[1]] > 0.5

"""**Step 10**: Now in this step, we will use a list of values for deciding the threshold of PCC."""

threshold_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

"""**Step 11**: Iterate through the `threshold_list` and for each value of the correlation threshold, denoted by `corr_threshold`, find the filtered set of columns to be used to train the model.

Now test the trained model corresponding to each value of Pearson Correlation Coefficient Threshold value and find the value of the threshold that gives use the best results by comparing the values of `precision` and `recall` obtained in each iteration.
"""

# import the required libraries
from sklearn.naive_bayes import GaussianNB   # for Classification model
from sklearn.metrics import classification_report  # for finding the accuracy through classification report

max_precision_recall = 0  # to store the max value of precision and recall obtained
best_threshold = 0  # to store the value of correlation threshold that gave the max values of precision and recall

# iterate through each value of the  `threshold_list`
for corr_threshold in threshold_list:
  # prepare a dictionary of the filtered columns for each threshold
  D = dict(corr_matrix[training_data.columns[1]] > corr_threshold)
  
  filtered_columns = []   # create an empty list to store the names of columns that will be used in feature selection
  # now, we will append the names of all the columns that will have a True value in the dictionary D
  for col in list(D.keys()):
    if D[col] == True:
      filtered_columns.append(col)  # append to the list

  # get the data of only those columns that have the correlation coefficient greater than `corr_threshold`
  filtered_training_data = training_data[filtered_columns]
  
  # the correct answers are stored in another dataframe `answers`
  answers = filtered_training_data[data.columns[1]]

  # the input features to be used are stored in another dataframe `input_features`
  input_features = filtered_training_data.drop(data.columns[1], axis=1)

  # check if all the columns have been filtered out, then no need for training the model with an empty dataset
  if(input_features.shape[1] == 0): # if no columns have been selected
    print("No columns selected for Pearson Correlation Threshold", corr_threshold)
    continue  # force the next iteration of the loop

  # create an object of GaussianNB
  naive_bayes_algo = GaussianNB()
  # training the model on the train data
  naive_bayes_algo.fit(X=input_features, y=answers) 

  # now filter the testing dataset accorfing the filtered columns obtained
  filtered_testing_data = testing_data[filtered_columns]
  testing_answers = filtered_testing_data[data.columns[1]]  # the correct asnwers to be used for testing 
  testing_input_features = filtered_testing_data.drop(data.columns[1], axis=1)  # the filterd testing dataset to be used for testing 
  
  # testing the trained model
  exam_answers = naive_bayes_algo.predict(X=testing_input_features)

  # comparing the original and obtained values
  report_dict = classification_report(y_true=testing_answers, y_pred=exam_answers, output_dict=True)  # for finding the values of precision and recall
  report = classification_report(y_true=testing_answers, y_pred=exam_answers)
  
  # find the sum of precision and recall
  sum = report_dict['macro avg']['precision'] + report_dict['macro avg']['recall']
  if sum > max_precision_recall:
    max_precision_recall = sum
    best_threshold = corr_threshold   # store the best value of threshold
  # print the classification report for each value of the correlation threshold
  print("Classification report for Pearson Correlation Threshold:", corr_threshold)
  print(report)

print("\n\n***************************************************\n")
print("Best value of Pearson Correlation Coefficient: ", best_threshold)

"""**This completes the final assignment.**"""