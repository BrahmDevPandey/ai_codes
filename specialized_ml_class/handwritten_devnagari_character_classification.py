# -*- coding: utf-8 -*-
"""handwritten_devnagari_character_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cuMf4FwaJNXQN0E6-bbKw8UFe3HPxwtP

#**Objective:**
###We will use a dataset available at `https://archive.ics.uci.edu/ml/machine-learning-databases/00389/DevanagariHandwrittenCharacterDataset.zip` to train a **Logistic Regression** model from sklearn library.

##**Libraries used:**
**numpy**: to create numpy arrays for storing the data of each individual image.

**matplotlib.pyplot**: to create plot of various images on the screen and also convert the images to numpy arrays format.

**sklearn.linear_model**: to train the Logistic Regression model on the dataset.

**sklearn.metric**: to compare the result of prediction with actual values using classification_report.

**os**: to access the `listdir()` funtion to get a list of folders and files present inside any directory on the drive

##**Step 1**: Change the directory to the `/content` directory for storing the dataset.
"""

!cd "/content"

"""##**Step 2**: Download the dataset from the link provided into the current directory."""

!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00389/DevanagariHandwrittenCharacterDataset.zip"

"""##**Step 3**: Unzip the archive to get the training and testing data folders."""

!unzip /content/DevanagariHandwrittenCharacterDataset.zip

"""##**Step 4**: Import the required libraries"""

import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

"""#**PREPARE THE TRAINING DATASET**

##**Step 5**: Create a list containing the data of all images in the form of numpy arrays
"""

# convert all the images into a dataset
base_path = "/content/DevanagariHandwrittenCharacterDataset/Train"  # the path to the Train folder
images_table = list()   # an empty list to store the list of all images data in np array format
diff_folders = os.listdir(base_path)  # get a list of all the folders in Train folder

for i in range(len(diff_folders)):  # iterate through each sub folder of the Train folder
  single_folder_path = base_path + "/" + diff_folders[i]  # path of a single folder inside the Train folder
  single_folder_images = os.listdir(single_folder_path)   # the list of all the images present inside the single folder
  for image_name in single_folder_images:   # now iterate over the list of all image names
    single_image_path = single_folder_path + "/" + image_name   # create a path of each of the image
    img_np_array = plt.imread(single_image_path)   # convert the image into np array
    reshaped_img_np_array = np.reshape(img_np_array, newshape=(1024,))  # reshape the 2d np array (32x32) into a 1d array of length 1024
    images_table.append(reshaped_img_np_array)  # append this reshaped array to the images_table list

"""##**Step 6**: See the length of the images_table list to verify that all images have been appended to it"""

print(len(images_table))

"""##**Step 7**: Now, convert the obtained final list to a 2d numpy array (just like a pandas dataframe). 
This should contain 78200 rows, each row having 1024 columns.

**Each row of this numpy array represents the data of one devnagari character with all the 1024 columns showing its features.**
"""

input_features = np.array(images_table)  # this will work as input features
print(input_features.shape)   # verify the shape of the obtained 2d array

"""##**Step 8**: Now create a list that will contain the names of each character, to be used as the label of each of the rows for training the model"""

answers = list()   # to create the answers
for folder_name in diff_folders:
  answers.extend([folder_name]*1700)

"""##**Step 9**: Convert the obtained list to a numpy array."""

answers = np.array(answers)   # convert it into an np array

"""##**Step 9**: Import the `LogisticRegression` model from `sklearn.linear_model` and create an object of it.

**Note**: Make sure to increase the value of `max_iter` argument (default 100) to 2000 to avoid `maximum depth reached` error.

"""

# training on the dataset
logistic_regression_algo = LogisticRegression(max_iter=2000)

"""#**TRAIN MODEL**
##**Step 10**: Train the logistic regression model on the created dataset.

###This will take around 25 minutes to complete.
"""

logistic_regression_algo.fit(X=input_features, y=answers)

"""#**PREPARE TESTING DATASET**

##**Step 11**: Similar to the process of preparing the training dataset, we will prepare the tesing dataset using the data of the images present in the `Test` folder.
"""

# now perform the testing by preparing a dataset of the testing features
test_base_path = "/content/DevanagariHandwrittenCharacterDataset/Test"  # path of the Test folder
test_folders = os.listdir(test_base_path)   # list of all folders present in the test folder
test_images_table = list()  # an array to store all the images data

for folder_name in test_folders:  # iterate through the list of folder inside test folder
  test_subfolders_path = test_base_path + "/" + folder_name  # get path of a single folder inside test folder
  for image_name in os.listdir(test_subfolders_path):   # iterate through each image of the single folder
    image_path = test_subfolders_path + "/" + image_name  # get path of the image
    test_img_np_array = plt.imread(image_path)  #  convert the image to a numpy array using matplotlib
    reshaped_test_img_np_array = np.reshape(test_img_np_array, newshape=(1024,))  # reshape the obtained 2d array (32x32) into a 1d array of length 1024
    test_images_table.append(reshaped_test_img_np_array)  # append the final reshaped array to the list

"""##**Step 12**: Convert the obtained list into a numpy array."""

# creating the test input features using a numpy array
test_input_features = np.array(test_images_table)
print(test_input_features.shape)  # see the shape of testing data

"""##**Step 13**: Create a numpy array of the real names of the folders to verify the working and accuracy of the model."""

# the real answers of test data
test_answers = list()
for folder_name in test_folders:
  test_answers.extend([folder_name]*300)   # list of 300 same names (since each character in testing dataset has 300 images for testing it)
test_answers = np.array(test_answers)   # convert test answers list to an np array

"""##**Step 14**: Test the model on the `test_input_features` dataset."""

exam_answers = logistic_regression_algo.predict(test_input_features)

"""##**Step 15**: Compare the obtained classification with the actual classifications of the characters using classification_report."""

report = classification_report(y_true=test_answers, y_pred=exam_answers)  # comparison
print(report)   #print the final report

"""#**RESULT**:
##We observed that the total accuracy of the model, when tested on the testing data was 73%.
"""