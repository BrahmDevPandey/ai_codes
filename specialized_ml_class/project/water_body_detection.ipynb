{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!cd /content"
      ],
      "metadata": {
        "id": "zPBaFPM2tONh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's say that you are a data scientist working at UNESCO, and you will use satellite imagery and deep learning image segmentation algorithms to assess changes to freshwater resources over time. Your task is to design and optimize a robust algorithm to identify water in satellite images, automatically and with high accuracy. Once validated, you will pass the algorithm to the data engineers at the United Nations Educational, Scientific and Cultural Organization (UNESCO). They will implement the algorithm on their servers, processing new imagery as it becomes available. "
      ],
      "metadata": {
        "id": "LIK-7kYcbRP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The exponential growth of satellite-based information over the past four decades has provided unprecedented opportunities to improve water resources management. Much of this satellite data is freely available. Using publicly available datasets and European Space Agency [Sentinel-2](https://sentinel.esa.int/web/sentinel/missions/sentinel-2/overview) satellite imagery, your task is to design and implement a machine learning algorithm that will automatically detect the occurrence of water pixels in Sentinel-2 imagery. You will use a set of state-of-the-art machine learning tools for deep learning image classification."
      ],
      "metadata": {
        "id": "qeaLznjccIVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The type of classification task you will develop is semantic segmentation, which is the classification of each pixel in an image (hence segmentation) into one of a few prespecified discrete labels/classes (hence semantic). A segmentation algorithm with only two classes is a binary segmentation algorithm. A specific form of deep learning algorithm known as a convolutional neural network (CNN) has consistently shown state-of-the-art performance in image classification tasks. You will learn U-Net, a CNN-based model suitable to image segmentation. You will learn how to modify the U-Net model to suit your specific purposes. This project will give you a basic understanding of how all these algorithms work."
      ],
      "metadata": {
        "id": "TnKXMiXFdL9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This project uses techniques in computer vision and artificial intelligence specifically for working with satellite data, but this knowledge can be applied more widely to other areas of computer vision. The building blocks of CNN-based algorithms are also important tools in any type of change detection problem using satellite imagery, such as:\n",
        "\n",
        "1.   Natural resource management (deforestation, land use, conservation, pollution, mining)\n",
        "2.   Natural hazards (fire, flooding, drought, severe weather, marine navigation)\n",
        "3.   Agriculture (identifying cropland impacted by natural disasters or pests)\n",
        "4.   Urban planning and monitoring (monitoring development, real estate valuation, investigating insurance claims, detecting illegal construction)\n",
        "\n"
      ],
      "metadata": {
        "id": "RMfDbfIadm2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other types of image segmentation tasks on images from ground-based or mobile cameras are used in a wide range of applications in the fields of self-driving cars (for example, to identify roads, sidewalks, and other features in autonomous vehicle footage), robotics, and so on."
      ],
      "metadata": {
        "id": "4ORe-Pjuef8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's first download the dataset from Kaggle located at this [URL](https://www.kaggle.com/datasets/franciscoescobar/satellite-images-of-water-bodies)"
      ],
      "metadata": {
        "id": "eF-hR-OttbJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Once we will download the dataset from Kaggle and ```unzip``` it, we will notice that there will be two directories inside the unzipped folder, that is ```Images``` and ```Masks```. Where ```Images``` directory will consist of images which will be feed to the specialized kind of CNN, called U-Net which will in turn produce the Predicted Mask, that is the Probability of each pixel in the image belonging to 'Water' Class and then this CNN will be trained using the corresponding Ground Truth Mask in the ```Masks``` directory.   "
      ],
      "metadata": {
        "id": "u7vlBgu5doVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In order to train our CNN first, we need our custom Python data ```generator``` which will ```yield``` the ```np.array``` of mini batches having size ```mb_size``` equal to the number of input Images as well as their Masks in a single mini batch. This ```generator``` can be easily created with the help of an example [here](https://keras.io/examples/vision/oxford_pets_image_segmentation/) under the section \"Prepare Sequence class to load & vectorize batches of data\"."
      ],
      "metadata": {
        "id": "4FMJ5ntxf1mU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Then we will create the U-Net CNN Architecture for performing Image Segmentation, as shown below:\n",
        "\n",
        "![U-Net Architecture](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-07-07_at_9.08.00_PM_rpNArED.png)"
      ],
      "metadata": {
        "id": "LQAizQJhhVQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This above model architecture can be easily created using ```keras``` library with the help of an example [here](https://keras.io/examples/vision/oxford_pets_image_segmentation/) under the section \"Prepare U-Net Xception-style model\" and furthermore, it can be trained with the help of an example [here](https://keras.io/examples/vision/oxford_pets_image_segmentation/) under the section \"Train the model\". "
      ],
      "metadata": {
        "id": "G8xhgXdBizwf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oz9nAs_1RTcK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}